{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-18 01:47:21.058044: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-18 01:47:21.061844: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-18 01:47:21.110615: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-18 01:47:22.067645: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "[nltk_data] Downloading package stopwords to /home/rafael/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/rafael/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/rafael/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to /home/rafael/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from treatment import get_ml_treated_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rafael/Dev/IA-SpamCheck/venv/lib/python3.10/site-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "classifier = tf.keras.models.Sequential()\n",
    "\n",
    "classifier.add(tf.keras.layers.Dense(\n",
    "    activation='relu', input_dim=1, units=5,\n",
    "    kernel_initializer='uniform'\n",
    "))\n",
    "classifier.add(tf.keras.layers.Dense(\n",
    "    activation='sigmoid', units=1, kernel_initializer='uniform'\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(\n",
    "    optimizer='adam', loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m X_train, X_test, y_train, y_test \u001b[39m=\u001b[39m get_ml_treated_data()\n",
      "File \u001b[0;32m~/Dev/IA-SpamCheck/treatment.py:39\u001b[0m, in \u001b[0;36mget_ml_treated_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_ml_treated_data\u001b[39m():\n\u001b[0;32m---> 39\u001b[0m     X, y \u001b[39m=\u001b[39m get_grouped_data()\n\u001b[1;32m     41\u001b[0m     \u001b[39mreturn\u001b[39;00m train_test_split(X\u001b[39m.\u001b[39mtoarray(), y, test_size\u001b[39m=\u001b[39m\u001b[39m0.2\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m)\n",
      "File \u001b[0;32m~/Dev/IA-SpamCheck/treatment.py:23\u001b[0m, in \u001b[0;36mget_grouped_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m df \u001b[39m=\u001b[39m generate_oversampled_data(df)\n\u001b[1;32m     21\u001b[0m \u001b[39m# print(df['Category'].value_counts())\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mMessage\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39;49m\u001b[39mMessage\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mapply(\u001b[39mlambda\u001b[39;49;00m x: finalpreprocess(x))\n\u001b[1;32m     25\u001b[0m tfidf \u001b[39m=\u001b[39m TfidfVectorizer(stop_words\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39menglish\u001b[39m\u001b[39m'\u001b[39m, max_features\u001b[39m=\u001b[39m\u001b[39m5000\u001b[39m)\n\u001b[1;32m     26\u001b[0m X \u001b[39m=\u001b[39m tfidf\u001b[39m.\u001b[39mfit_transform(df[\u001b[39m'\u001b[39m\u001b[39mMessage\u001b[39m\u001b[39m'\u001b[39m])\n",
      "File \u001b[0;32m~/Dev/IA-SpamCheck/venv/lib/python3.10/site-packages/pandas/core/series.py:4904\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m   4769\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\n\u001b[1;32m   4770\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   4771\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4776\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m   4777\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[1;32m   4778\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   4779\u001b[0m \u001b[39m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4780\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4895\u001b[0m \u001b[39m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4896\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m   4897\u001b[0m     \u001b[39mreturn\u001b[39;00m SeriesApply(\n\u001b[1;32m   4898\u001b[0m         \u001b[39mself\u001b[39;49m,\n\u001b[1;32m   4899\u001b[0m         func,\n\u001b[1;32m   4900\u001b[0m         convert_dtype\u001b[39m=\u001b[39;49mconvert_dtype,\n\u001b[1;32m   4901\u001b[0m         by_row\u001b[39m=\u001b[39;49mby_row,\n\u001b[1;32m   4902\u001b[0m         args\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m   4903\u001b[0m         kwargs\u001b[39m=\u001b[39;49mkwargs,\n\u001b[0;32m-> 4904\u001b[0m     )\u001b[39m.\u001b[39;49mapply()\n",
      "File \u001b[0;32m~/Dev/IA-SpamCheck/venv/lib/python3.10/site-packages/pandas/core/apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1424\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_compat()\n\u001b[1;32m   1426\u001b[0m \u001b[39m# self.func is Callable\u001b[39;00m\n\u001b[0;32m-> 1427\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[0;32m~/Dev/IA-SpamCheck/venv/lib/python3.10/site-packages/pandas/core/apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1501\u001b[0m \u001b[39m# row-wise access\u001b[39;00m\n\u001b[1;32m   1502\u001b[0m \u001b[39m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m \u001b[39m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[1;32m   1504\u001b[0m \u001b[39m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[1;32m   1505\u001b[0m \u001b[39m#  Categorical (GH51645).\u001b[39;00m\n\u001b[1;32m   1506\u001b[0m action \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(obj\u001b[39m.\u001b[39mdtype, CategoricalDtype) \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1507\u001b[0m mapped \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39;49m_map_values(\n\u001b[1;32m   1508\u001b[0m     mapper\u001b[39m=\u001b[39;49mcurried, na_action\u001b[39m=\u001b[39;49maction, convert\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_dtype\n\u001b[1;32m   1509\u001b[0m )\n\u001b[1;32m   1511\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mapped) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(mapped[\u001b[39m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1512\u001b[0m     \u001b[39m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1513\u001b[0m     \u001b[39m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1514\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39m_constructor_expanddim(\u001b[39mlist\u001b[39m(mapped), index\u001b[39m=\u001b[39mobj\u001b[39m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/Dev/IA-SpamCheck/venv/lib/python3.10/site-packages/pandas/core/base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[1;32m    919\u001b[0m     \u001b[39mreturn\u001b[39;00m arr\u001b[39m.\u001b[39mmap(mapper, na_action\u001b[39m=\u001b[39mna_action)\n\u001b[0;32m--> 921\u001b[0m \u001b[39mreturn\u001b[39;00m algorithms\u001b[39m.\u001b[39;49mmap_array(arr, mapper, na_action\u001b[39m=\u001b[39;49mna_action, convert\u001b[39m=\u001b[39;49mconvert)\n",
      "File \u001b[0;32m~/Dev/IA-SpamCheck/venv/lib/python3.10/site-packages/pandas/core/algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1741\u001b[0m values \u001b[39m=\u001b[39m arr\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m   1742\u001b[0m \u001b[39mif\u001b[39;00m na_action \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1743\u001b[0m     \u001b[39mreturn\u001b[39;00m lib\u001b[39m.\u001b[39;49mmap_infer(values, mapper, convert\u001b[39m=\u001b[39;49mconvert)\n\u001b[1;32m   1744\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1745\u001b[0m     \u001b[39mreturn\u001b[39;00m lib\u001b[39m.\u001b[39mmap_infer_mask(\n\u001b[1;32m   1746\u001b[0m         values, mapper, mask\u001b[39m=\u001b[39misna(values)\u001b[39m.\u001b[39mview(np\u001b[39m.\u001b[39muint8), convert\u001b[39m=\u001b[39mconvert\n\u001b[1;32m   1747\u001b[0m     )\n",
      "File \u001b[0;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Dev/IA-SpamCheck/treatment.py:23\u001b[0m, in \u001b[0;36mget_grouped_data.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     19\u001b[0m df \u001b[39m=\u001b[39m generate_oversampled_data(df)\n\u001b[1;32m     21\u001b[0m \u001b[39m# print(df['Category'].value_counts())\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mMessage\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39mMessage\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: finalpreprocess(x))\n\u001b[1;32m     25\u001b[0m tfidf \u001b[39m=\u001b[39m TfidfVectorizer(stop_words\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39menglish\u001b[39m\u001b[39m'\u001b[39m, max_features\u001b[39m=\u001b[39m\u001b[39m5000\u001b[39m)\n\u001b[1;32m     26\u001b[0m X \u001b[39m=\u001b[39m tfidf\u001b[39m.\u001b[39mfit_transform(df[\u001b[39m'\u001b[39m\u001b[39mMessage\u001b[39m\u001b[39m'\u001b[39m])\n",
      "File \u001b[0;32m~/Dev/IA-SpamCheck/utils/preprocess.py:104\u001b[0m, in \u001b[0;36mfinalpreprocess\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfinalpreprocess\u001b[39m(text: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mstr\u001b[39m:\n\u001b[0;32m--> 104\u001b[0m     \u001b[39mreturn\u001b[39;00m lemmatizer(stopword(preprocess(text)))\n",
      "File \u001b[0;32m~/Dev/IA-SpamCheck/utils/preprocess.py:98\u001b[0m, in \u001b[0;36mlemmatizer\u001b[0;34m(string)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlemmatizer\u001b[39m(string):\n\u001b[0;32m---> 98\u001b[0m     word_pos_tags \u001b[39m=\u001b[39m nltk\u001b[39m.\u001b[39;49mpos_tag(word_tokenize(string))\n\u001b[1;32m     99\u001b[0m     a \u001b[39m=\u001b[39m [wl\u001b[39m.\u001b[39mlemmatize(tag[\u001b[39m0\u001b[39m], get_wordnet_pos(tag[\u001b[39m1\u001b[39m])) \u001b[39mfor\u001b[39;00m idx, tag \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(word_pos_tags)]\n\u001b[1;32m    100\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(a)\n",
      "File \u001b[0;32m~/Dev/IA-SpamCheck/venv/lib/python3.10/site-packages/nltk/tag/__init__.py:166\u001b[0m, in \u001b[0;36mpos_tag\u001b[0;34m(tokens, tagset, lang)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    142\u001b[0m \u001b[39mUse NLTK's currently recommended part of speech tagger to\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[39mtag the given list of tokens.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[39m:rtype: list(tuple(str, str))\u001b[39;00m\n\u001b[1;32m    164\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    165\u001b[0m tagger \u001b[39m=\u001b[39m _get_tagger(lang)\n\u001b[0;32m--> 166\u001b[0m \u001b[39mreturn\u001b[39;00m _pos_tag(tokens, tagset, tagger, lang)\n",
      "File \u001b[0;32m~/Dev/IA-SpamCheck/venv/lib/python3.10/site-packages/nltk/tag/__init__.py:123\u001b[0m, in \u001b[0;36m_pos_tag\u001b[0;34m(tokens, tagset, tagger, lang)\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mtokens: expected a list of strings, got a string\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    122\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 123\u001b[0m     tagged_tokens \u001b[39m=\u001b[39m tagger\u001b[39m.\u001b[39;49mtag(tokens)\n\u001b[1;32m    124\u001b[0m     \u001b[39mif\u001b[39;00m tagset:  \u001b[39m# Maps to the specified tagset.\u001b[39;00m\n\u001b[1;32m    125\u001b[0m         \u001b[39mif\u001b[39;00m lang \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39meng\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[0;32m~/Dev/IA-SpamCheck/venv/lib/python3.10/site-packages/nltk/tag/perceptron.py:187\u001b[0m, in \u001b[0;36mPerceptronTagger.tag\u001b[0;34m(self, tokens, return_conf, use_tagdict)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m tag:\n\u001b[1;32m    186\u001b[0m     features \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_features(i, word, context, prev, prev2)\n\u001b[0;32m--> 187\u001b[0m     tag, conf \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mpredict(features, return_conf)\n\u001b[1;32m    188\u001b[0m output\u001b[39m.\u001b[39mappend((word, tag, conf) \u001b[39mif\u001b[39;00m return_conf \u001b[39m==\u001b[39m \u001b[39mTrue\u001b[39;00m \u001b[39melse\u001b[39;00m (word, tag))\n\u001b[1;32m    190\u001b[0m prev2 \u001b[39m=\u001b[39m prev\n",
      "File \u001b[0;32m~/Dev/IA-SpamCheck/venv/lib/python3.10/site-packages/nltk/tag/perceptron.py:69\u001b[0m, in \u001b[0;36mAveragedPerceptron.predict\u001b[0;34m(self, features, return_conf)\u001b[0m\n\u001b[1;32m     66\u001b[0m         scores[label] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m value \u001b[39m*\u001b[39m weight\n\u001b[1;32m     68\u001b[0m \u001b[39m# Do a secondary alphabetic sort, for stability\u001b[39;00m\n\u001b[0;32m---> 69\u001b[0m best_label \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclasses, key\u001b[39m=\u001b[39;49m\u001b[39mlambda\u001b[39;49;00m label: (scores[label], label))\n\u001b[1;32m     70\u001b[0m \u001b[39m# compute the confidence\u001b[39;00m\n\u001b[1;32m     71\u001b[0m conf \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_softmax(scores)) \u001b[39mif\u001b[39;00m return_conf \u001b[39m==\u001b[39m \u001b[39mTrue\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Dev/IA-SpamCheck/venv/lib/python3.10/site-packages/nltk/tag/perceptron.py:69\u001b[0m, in \u001b[0;36mAveragedPerceptron.predict.<locals>.<lambda>\u001b[0;34m(label)\u001b[0m\n\u001b[1;32m     66\u001b[0m         scores[label] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m value \u001b[39m*\u001b[39m weight\n\u001b[1;32m     68\u001b[0m \u001b[39m# Do a secondary alphabetic sort, for stability\u001b[39;00m\n\u001b[0;32m---> 69\u001b[0m best_label \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses, key\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m label: (scores[label], label))\n\u001b[1;32m     70\u001b[0m \u001b[39m# compute the confidence\u001b[39;00m\n\u001b[1;32m     71\u001b[0m conf \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_softmax(scores)) \u001b[39mif\u001b[39;00m return_conf \u001b[39m==\u001b[39m \u001b[39mTrue\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = get_ml_treated_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.fit(X_train, y_train, batch_size=1, epochs=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
